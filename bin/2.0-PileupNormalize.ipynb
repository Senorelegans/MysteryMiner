{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T23:51:09.895464Z",
     "start_time": "2020-01-17T23:51:09.884099Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "from subprocess import call\n",
    "import subprocess\n",
    "import sys # system libraries, like arguments (argv)\n",
    "import re # regular expressions\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T23:51:10.911461Z",
     "start_time": "2020-01-17T23:51:10.907628Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def makeFolders(folder_list):\n",
    "    for directory in folder_list:\n",
    "        if not directory: # Make sure not an empty string \"\"\n",
    "            continue\n",
    "        else:\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T23:51:12.039219Z",
     "start_time": "2020-01-17T23:51:12.033790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'751'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"NODE_8_length_751_\"\n",
    "s = s.split(\"length\")[1]\n",
    "s = s.split(\"_\")[1]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T17:51:35.048441Z",
     "start_time": "2020-01-17T17:51:35.013498Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class Pileup(): \n",
    "    def __init__(self, NF_out,  explicit=False, map_quality=15):\n",
    "        self.explicit = explicit\n",
    "        self.NF_out = NF_out\n",
    "        self.wkdir = f'{self.NF_out}/unmapped/final'\n",
    "        self.df_norm = pd.DataFrame()\n",
    "#         self.col_data = col_data\n",
    "#         self.df_col = pd.read_csv(self.col_data,sep=\"\\t\",names = [\"sample\",\"condition\"])\n",
    "#         self.condition_list = self.df_col[\"condition\"].unique()\n",
    "#         self.levels = [\"all\",\"single\",\"group\"]\n",
    "        self.levels = [\"all\"]\n",
    "\n",
    "    def pe(self, s):\n",
    "        if self.explicit:\n",
    "            print(s) \n",
    "            \n",
    "   \n",
    "            \n",
    "    def get_star_output(self):\n",
    "        \"\"\"This function will return a df from star of all reads\"\"\"\n",
    "        starpath = f'{self.NF_out}/qc/star_mapstats'\n",
    "        filelist = glob.glob(starpath+\"/*Log.final.out\")\n",
    "        df = pd.DataFrame(columns=[\"sample\",\"input\",\"unique\",\"multi\"])\n",
    "        x = 0\n",
    "        \n",
    "        \n",
    "        for f1 in filelist:\n",
    "            with open(f1,\"r\") as infile:\n",
    "                input_reads_list = []\n",
    "                unique_reads_list = []\n",
    "                multi_reads_list = []\n",
    "                for line in infile:\n",
    "                    if \"Number of input reads\" in line:\n",
    "                        scl = [m.start() for m in re.finditer(r\"\\t\",line)]  \n",
    "                        input_reads = line[ scl[0]:].strip(\"\\t\")\n",
    "                        input_reads_list.append(int(input_reads))\n",
    "                    if \"Uniquely mapped reads number\" in line:\n",
    "                        scl = [m.start() for m in re.finditer(r\"\\t\",line)]  \n",
    "                        unique_reads = line[ scl[0]:].strip(\"\\t\")\n",
    "                        unique_reads_list.append(int(unique_reads))\n",
    "                    if \"Number of reads mapped to multiple loci\" in line:\n",
    "                        scl = [m.start() for m in re.finditer(r\"\\t\",line)]  \n",
    "                        multi_reads = line[ scl[0]:].strip(\"\\t\")\n",
    "                        multi_reads_list.append(int(multi_reads))\n",
    "                sample = os.path.basename(f1).replace(\"Log.final.out\",\"\")\n",
    "                df.loc[x] = pd.Series({\"sample\":sample, \"unique\": unique_reads_list[0], \"input\":input_reads_list[0],\"multi\":multi_reads_list[0]})\n",
    "            x = x + 1\n",
    "            \n",
    "        df[\"total_mapped\"] = (df[\"unique\"] + df[\"multi\"]).astype(int)\n",
    "        df[\"lowest_total_mapped\"] = df[\"total_mapped\"].min()\n",
    "        df[\"mapped_norm\"] =  df[\"lowest_total_mapped\"] / df[\"total_mapped\"]\n",
    " \n",
    "           \n",
    "        df.to_csv(starpath+\"/starmapstats.txt\",sep=\"\\t\",index=None)\n",
    "        self.df_norm = df\n",
    "                    \n",
    "\n",
    "        \n",
    "        \n",
    "    def readCSV(self,f):\n",
    "        names = [\"contig\",\"start\",\"base\",\"num_reads\",\"read_bases\",\"base_quality\",\"map_quality\"]\n",
    "        names = [\"contig\",\"start\",\"base\",\"num_reads\"]\n",
    "        usecols=range(4)\n",
    "        df = pd.read_csv(f,sep=\"\\t\",engine=\"python\", names=names,usecols=usecols)\n",
    "        return df\n",
    "        \n",
    "        \n",
    "    def parsePileup(self):\n",
    "        self.get_star_output()\n",
    "\n",
    "        for level in self.levels:\n",
    "            if self.explicit:\n",
    "                self.pe(f'Working on {level} --- ')\n",
    "\n",
    "                # Get some contigs for index\n",
    "            files = glob.glob(f'{self.wkdir}/pileup/{level}/*pileup.txt')\n",
    "            f = files[0]\n",
    "            df = self.readCSV(f)\n",
    "            df = df.drop_duplicates(subset=\"contig\")\n",
    "            df_final = pd.DataFrame()\n",
    "            df_final[\"contig\"] = df[\"contig\"]\n",
    "                \n",
    "            for f in files:\n",
    "                self.pe(\"---------------\")\n",
    "                filename = os.path.basename(f).replace(f\"_unmapped_{level}_pileup.txt\",\"\")\n",
    "                self.pe(f' Working on file {filename}')\n",
    "\n",
    "                df = self.readCSV(f)\n",
    "                df[\"length\"] = df[\"contig\"].str.split(\"length\",expand=True)[1].str.split(\"_\",expand=True)[1].astype(int)\n",
    "                g = df.groupby([\"contig\"])\n",
    "                df2 = g.sum()\n",
    "                del df2[\"start\"]\n",
    "                del df2[\"length\"]\n",
    "\n",
    "                df_length = df[[\"contig\",\"length\"]]\n",
    "                df_length = df_length.drop_duplicates(subset=\"contig\")\n",
    "                df = pd.merge(df_length,df2,on=\"contig\",how=\"right\")\n",
    "\n",
    "\n",
    "                df[\"coverage\"] = df[\"num_reads\"] / df[\"length\"]\n",
    "                df[\"coverage\"] = df[\"coverage\"].astype(float)\n",
    "\n",
    "\n",
    "\n",
    "                # Get norm from star output\n",
    "                norm = self.df_norm[self.df_norm[\"sample\"]==filename][\"mapped_norm\"]\n",
    "                df[\"norm\"] = float(norm)\n",
    "\n",
    "                df[\"norm\"] = df[\"norm\"].astype(float)\n",
    "\n",
    "\n",
    "                df[\"coverage_norm\"] = df[\"coverage\"] * df[\"norm\"]\n",
    "\n",
    "                makeFolders([f'{self.wkdir}/pileupParsedPerFile/',f'{self.wkdir}/pileupParsedPerFile/{level}'])\n",
    "                out = f'{self.wkdir}/pileupParsedPerFile/{level}/{filename}_pileupParsed.txt'\n",
    "                df.to_csv(out,sep=\"\\t\",index=None)\n",
    "                df2 = df[[\"contig\"]].copy()\n",
    "                df2[filename] = df[\"coverage_norm\"]\n",
    "\n",
    "                \n",
    "                \n",
    "                df_final = pd.merge(df_final,df2,on=\"contig\",how=\"outer\")\n",
    "                \n",
    "            makeFolders([f'{self.wkdir}/pileupCoverageNormalized/'])\n",
    "            out = f'{self.wkdir}/pileupCoverageNormalized/{level}_pileupCoverageNormalized.txt'\n",
    "            df_final = df_final.fillna(0.0)\n",
    "            df_final.to_csv(out,sep=\"\\t\",index=None)                \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T00:07:25.595331Z",
     "start_time": "2020-01-17T23:54:12.675345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on all --- \n",
      "---------------\n",
      " Working on file LP00023_GT17-02957_ATTCAGAA-GTCAGTAC_S17_L005\n",
      "---------------\n",
      " Working on file LP00086_GT17-02929_CGCTCATT-GCCTCTAT_S12_L003\n",
      "---------------\n",
      " Working on file LP00102_GT17-02921_ATTACTCG-TAAGATTA_S7_L002\n",
      "---------------\n",
      " Working on file LP00017_GT17-02941_CGCTCATT-GTCAGTAC_S22_L006\n",
      "---------------\n",
      " Working on file LP00260_GT17-03011_TCCGGAGA-GCCTCTAT_S24_L006\n",
      "---------------\n",
      " Working on file LP00069_GT17-02951_GAATTCGT-TCAGAGCC_S26_L007\n",
      "---------------\n",
      " Working on file LP00270_GT17-02995_AGCGATAG-GCCTCTAT_S7_L002\n",
      "---------------\n",
      " Working on file LP00043_GT17-02964_CTGAAGCT-AGGATAGG_S24_L006\n",
      "---------------\n",
      " Working on file LP0R039_GT17-03001_TCTCGCGC-TAAGATTA_S15_L004\n",
      "---------------\n",
      " Working on file LP00221_GT17-02971_TAATGCGC-TAAGATTA_S25_L007\n",
      "---------------\n",
      " Working on file LP0R156_GT17-03021_ATTACTCG-GTCAGTAC_S15_L004\n",
      "---------------\n",
      " Working on file LP0R138_GT17-02989_CGGCTATG-GTCAGTAC_S1_L001\n",
      "---------------\n",
      " Working on file LP0R124_GT17-03017_ATTACTCG-TAAGATTA_S30_L008\n",
      "---------------\n",
      " Working on file LP00310_GT17-02960_CTGAAGCT-AGGCTATA_S32_L008\n",
      "---------------\n",
      " Working on file LP00005_GT17-02918_TCCGGAGA-AGGATAGG_S4_L001\n",
      "---------------\n",
      " Working on file LP0R074_GT17-02973_CTGAAGCT-GTCAGTAC_S30_L008\n",
      "---------------\n",
      " Working on file LP00301_GT17-03019_TCCGGAGA-TAAGATTA_S29_L008\n",
      "---------------\n",
      " Working on file LP00307_GT17-02944_ATTCAGAA-AGGCTATA_S9_L003\n",
      "---------------\n",
      " Working on file LP00275_GT17-02998_AGCGATAG-AGGATAGG_S12_L003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-67c10409c2b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_star_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsePileup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-3529db0349cb>\u001b[0m in \u001b[0;36mparsePileup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"length\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"contig\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"length\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"contig\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1841\u001b[0m                 )\n\u001b[1;32m   1842\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1843\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1845\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, pat, n, expand)\u001b[0m\n\u001b[1;32m   2560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"str_split\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"side\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"method\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"rsplit\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_wrap_result\u001b[0;34m(self, result, use_codes, name, expand, fill_value)\u001b[0m\n\u001b[1;32m   2060\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m                 \u001b[0mcons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_expanddim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2063\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m                 \u001b[0;31m# Must be a Series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    460\u001b[0m                             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                     \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m                     \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# from BlockManager perspective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             val = sanitize_array(\n\u001b[0;32m--> 323\u001b[0;31m                 \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             )\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     ):\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0minferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minferred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"period\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "            \n",
    "# NF = \"/Users/m/Google_Drive/Scripts/2019/biome/biome_shared/general/datasets/Z_RNAseq-Biome-master\"\n",
    "\n",
    "# # NF =\"/Users/m/Google_Drive/Scripts/2019/biome/biome_shared/general/datasets/trem2/RNAseq-Biome-master\"\n",
    "\n",
    "# NF_out = f\"{NF}/NF_OUT\" \n",
    "# col_data = f\"{NF}/sample_table.txt\"\n",
    "\n",
    "# P = Pileup(NF_out=NF_out,  \n",
    "#              explicit=True,\n",
    "#             )\n",
    "\n",
    "# P.get_star_output()\n",
    "# P.parsePileup()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T17:51:36.909309Z",
     "start_time": "2020-01-17T17:51:36.905745Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import argparse\n",
    "def parse_arguments():\n",
    "        parser = argparse.ArgumentParser(description='filter quantify and graph') \n",
    "        parser.add_argument('--Nextflow_Out', action= 'store', metavar='--Nextflow_Out') \n",
    "\n",
    "        args = parser.parse_args()\n",
    "        return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T17:51:37.287943Z",
     "start_time": "2020-01-17T17:51:37.278937Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--Nextflow_Out --Nextflow_Out]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/m/Library/Jupyter/runtime/kernel-3001c855-e971-41c5-b457-a882063e7795.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "if __name__==\"__main__\":\n",
    "    args = parse_arguments()\n",
    "    print(\"Normalizing pileup\")\n",
    "    NF_out = args.Nextflow_Out\n",
    "    \n",
    "    P = Pileup(NF_out=NF_out, \n",
    "             explicit=True,\n",
    "            )\n",
    "    P.parsePileup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T17:51:39.010155Z",
     "start_time": "2020-01-17T17:51:38.695896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 2.0-PileupNormalize.ipynb to nb_2.0-PileupNormalize.py\r\n"
     ]
    }
   ],
   "source": [
    "import fire\n",
    "!python3 notebook2script.py 2.0-PileupNormalize.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
