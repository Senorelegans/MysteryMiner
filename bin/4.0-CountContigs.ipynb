{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:15.468324Z",
     "start_time": "2020-05-14T17:11:15.449732Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "from subprocess import call\n",
    "import subprocess\n",
    "import sys # system libraries, like arguments (argv)\n",
    "import re # regular expressions\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:15.603856Z",
     "start_time": "2020-05-14T17:11:15.600008Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def makeFolders(folder_list):\n",
    "    for directory in folder_list:\n",
    "        if not directory: # Make sure not an empty string \"\"\n",
    "            continue\n",
    "        else:\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:16.527629Z",
     "start_time": "2020-05-14T17:11:16.465857Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class fastQ():\n",
    "    \n",
    "    def __init__(self, NF_out, col_data):\n",
    "        self.NF_out = NF_out\n",
    "        self.wkdir = f'{self.NF_out}/unmapped/final'\n",
    "        self.col_data = col_data\n",
    "        self.df_col = pd.read_csv(self.col_data,sep=\"\\t\",names = [\"sample\",\"condition\"])\n",
    "        self.condition_list = self.df_col[\"condition\"].unique()\n",
    "        self.df_fq = pd.DataFrame()\n",
    "        \n",
    "        \n",
    "    def getfqCountInitial(self, f):\n",
    "        df = pd.read_csv(f,sep=\" \",names=[\"count\"])\n",
    "        count = df[\"count\"].iloc[0]\n",
    "        count = int(int(count) / 4)\n",
    "        name = os.path.basename(f)\n",
    "        name = name.replace(\"_R1_fastqtrim_count.txt\",\"\")\n",
    "        name = name.replace(\"_R1_fastq_count.txt\",\"\")\n",
    "        return name, count        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def getfqCount(self, f):\n",
    "        df = pd.read_csv(f,sep=\" \",names=[\"count\",\"name\"])\n",
    "        count = df[\"count\"].iloc[0]\n",
    "        count = int(int(count) / 4)\n",
    "        name = os.path.basename(f)\n",
    "        name = name.split(\"Unmapped\")[0]\n",
    "        return name, count\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fastqtonumber(self):\n",
    "        fq_path = f'{self.NF_out}/unmapped/final/filter/fastq/'\n",
    "        start_fqs = sorted(glob.glob(f'{self.NF_out}/qc/fastq_count/*count.txt'))\n",
    "        trim_fqs = sorted(glob.glob(f'{self.NF_out}/qc/fastqtrim_count/*count.txt'))\n",
    "        unmapped_fqs = sorted(glob.glob(f'{fq_path}/initial/*count.txt'))\n",
    "        afterbowtie_fqs = sorted(glob.glob(f'{fq_path}/bowtie2/*bowtie2_count.txt'))\n",
    "        magicblast_fqs = sorted(glob.glob(f'{fq_path}/magicblast/*magicblast_count.txt')) \n",
    "\n",
    "        df = pd.DataFrame(columns = [\"sample\",\"count\",\"step\"])\n",
    "        f = unmapped_fqs[0]\n",
    "        x = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        for f in start_fqs:\n",
    "            name, count = self.getfqCountInitial(f)\n",
    "            df.loc[x] = pd.Series( {\"sample\":name,\"count\":count, \"step\":\"initial_reads\"} )\n",
    "            df[\"count\"] = df[\"count\"].astype(int)\n",
    "            x = x + 1        \n",
    "        \n",
    "        \n",
    "        for f in trim_fqs:\n",
    "            name, count = self.getfqCountInitial(f)\n",
    "            df.loc[x] = pd.Series( {\"sample\":name,\"count\":count, \"step\":\"trimmed_reads\"} )\n",
    "            df[\"count\"] = df[\"count\"].astype(int)\n",
    "            x = x + 1        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for f in unmapped_fqs:\n",
    "            name, count = self.getfqCount(f)\n",
    "            df.loc[x] = pd.Series( {\"sample\":name,\"count\":count, \"step\":\"unmapped_star\"} )\n",
    "            df[\"count\"] = df[\"count\"].astype(int)\n",
    "            x = x + 1\n",
    "        for f in afterbowtie_fqs:\n",
    "            name, count = self.getfqCount(f)\n",
    "            df.loc[x] = pd.Series( {\"sample\":name,\"count\":count, \"step\":\"unmapped_bowtie2\"} )\n",
    "            x = x + 1 \n",
    "        for f in magicblast_fqs:\n",
    "            name, count = self.getfqCount(f)\n",
    "            df.loc[x] = pd.Series( {\"sample\":name,\"count\":count, \"step\":\"unmapped_magicblast\"} )\n",
    "            x = x + 1               \n",
    "            \n",
    "        df_star = df[df[\"step\"]==\"initial_reads\"]\n",
    "        df_merge = pd.merge(self.df_col,df_star, on=\"sample\")\n",
    "        df_merge = df_merge.rename(columns={\"count\":\"initial_reads\"})\n",
    "        del df_merge[\"step\"]\n",
    "        \n",
    "        df_temp = df[df[\"step\"]==\"trimmed_reads\"]\n",
    "        df_merge = pd.merge(df_merge,df_temp, on=\"sample\")\n",
    "        df_merge = df_merge.rename(columns={\"count\":\"trimmed_reads\"})\n",
    "        del df_merge[\"step\"] \n",
    "        \n",
    "        df_temp = df[df[\"step\"]==\"unmapped_star\"]\n",
    "        df_merge = pd.merge(df_merge,df_temp, on=\"sample\")\n",
    "        df_merge = df_merge.rename(columns={\"count\":\"unmapped_star\"})\n",
    "        del df_merge[\"step\"]        \n",
    "        \n",
    "        df_temp = df[df[\"step\"]==\"unmapped_bowtie2\"]\n",
    "        df_merge = pd.merge(df_merge,df_temp, on=\"sample\")\n",
    "        df_merge = df_merge.rename(columns={\"count\":\"unmapped_bowtie2\"})\n",
    "        del df_merge[\"step\"]\n",
    "        \n",
    "        df_temp = df[df[\"step\"]==\"unmapped_magicblast\"]\n",
    "        df_merge = pd.merge(df_merge,df_temp, on=\"sample\")\n",
    "        df_merge = df_merge.rename(columns={\"count\":\"unmapped_magicblast\"})\n",
    "        del df_merge[\"step\"]  \n",
    "        df = df_merge\n",
    "\n",
    "        \n",
    "        df_initial = pd.read_csv(f\"{self.NF_out}/qc/star_mapstats/starmapstats.txt\",sep=\"\\t\")\n",
    "\n",
    "        df = pd.merge(df,df_initial,on=\"sample\")\n",
    " \n",
    "\n",
    "\n",
    "        gb = df.groupby(\"condition\").sum() \n",
    "        gb[\"sample\"] = gb.index\n",
    "        gb[\"condition\"] = gb.index\n",
    "        \n",
    "        df_all = pd.DataFrame(df.sum().iloc[2:])\n",
    "        df_all = df_all.rename(columns={0:\"all\"}).T\n",
    "        df_all[\"sample\"] = \"all\"\n",
    "        df_all[\"condition\"] = \"all\"\n",
    "        \n",
    "        \n",
    "        df = pd.concat([df_all,gb,df], sort=False)\n",
    "        \n",
    "        \n",
    "        df[\"trimmed_reads_removed\"] = df[\"initial_reads\"] - df[\"trimmed_reads\"]        \n",
    "        df[\"mapped_star\"] = df[\"trimmed_reads\"] - df[\"unmapped_star\"]\n",
    "        df[\"mapped_bowtie2\"] = df[\"unmapped_star\"] - df[\"unmapped_bowtie2\"]\n",
    "        \n",
    "#         df[\"mapped_magicblast\"] = df[\"unmapped_bowtie2\"] - df[\"unmapped_magicblast\"]\n",
    "        df[\"unmapped_final\"] = df[\"initial_reads\"] - df[\"trimmed_reads_removed\"] - df[\"mapped_star\"] - df[\"mapped_bowtie2\"]\n",
    "        \n",
    "        df[\"trimmed_reads_removed_perc\"] = df[\"trimmed_reads_removed\"] / df[\"initial_reads\"]\n",
    "        df[\"mapped_star_perc\"] = df[\"mapped_star\"] / df[\"initial_reads\"] \n",
    "        df[\"mapped_bowtie2_perc\"] = df[\"mapped_bowtie2\"] / df[\"initial_reads\"] \n",
    "#         df[\"mapped_magicblast_perc\"] = df[\"mapped_magicblast\"] / df[\"initial_reads\"] \n",
    "        df[\"unmapped_final_perc\"] = df[\"unmapped_final\"]  / df[\"initial_reads\"]       \n",
    "\n",
    "        \n",
    "                \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        self.df_fq = df\n",
    "        \n",
    "        \n",
    "                \n",
    "        df = df[[\"sample\",\"condition\",\"initial_reads\",\"trimmed_reads\",\"trimmed_reads_removed\",\n",
    "                 \"mapped_star\",\n",
    "                 \"unmapped_star\",\"mapped_bowtie2\",\"unmapped_bowtie2\",\"unmapped_final\" ,  \n",
    "        \"trimmed_reads_removed_perc\",\n",
    "        \"mapped_star_perc\",\n",
    "        \"mapped_bowtie2_perc\" ,\n",
    "        \"unmapped_final_perc\"   ]]\n",
    "\n",
    "#         df[\"percent mapped star\"] = df[\"mapped_star\"] / df[\"input\"]\n",
    "#         df[\"percent mapped bowtie2\"] = df[\"mapped_bowtie2\"] / df[\"input\"]\n",
    "#         df[\"percent unmapped\"] = df[\"unmapped_final\"] / df[\"input\"]\n",
    "\n",
    "        \n",
    "        df.to_csv(f'{fq_path}/fastq_amount_df.csv',sep=\"\\t\",index=None)\n",
    "\n",
    "        \n",
    "        \n",
    "    def plotBarChartUnmapped(self):\n",
    "        df = self.df_fq\n",
    "        df = df[[\"sample\",\"unmapped_star\",\"unmapped_bowtie2\",\"unmapped_magicblast\"]]\n",
    "        df.index = df[\"sample\"]\n",
    "        # del df_stacked[\"condition\"]\n",
    "        fig = df.plot(kind='bar',  figsize=(20, 16), fontsize=15).get_figure()\n",
    "\n",
    "        self.barpath = f'{self.NF_out}/plots/barchart'\n",
    "        makeFolders([f'{self.NF_out}/plots',self.barpath])\n",
    "        fig.savefig(f'{self.barpath}/unmapped_reads.pdf')\n",
    "        \n",
    "\n",
    "        \n",
    "#         ${unmappedPath}/final/filter/fastq/concatCondition\"\n",
    "#         wc -l group_${condition}_unmapped_R1.fastq > group_${condition}_unmapped_fastq_count.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:18.601031Z",
     "start_time": "2020-05-14T17:11:18.511413Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# col_data = \"/Users/m/Google_Drive/Scripts/2019/biome/biome_shared/general/datasets/Z_RNAseq-Biome-master/sample_table.txt\"\n",
    "# NF_out = \"/Users/m/Google_Drive/Scripts/2019/biome/biome_shared/general/datasets/Z_RNAseq-Biome-master/NF_OUT\"\n",
    "\n",
    "\n",
    "col_data = \"/Users/m/Google_Drive/Scripts/2019/biome/biome_shared/general/datasets/chlamydia/RNAseq-Biome-master/sample_table.txt\"\n",
    "NF_out = \"/Users/m/Google_Drive/Scripts/2019/biome/biome_shared/general/datasets/chlamydia/RNAseq-Biome-master/NF_OUT\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "F = fastQ(NF_out = NF_out, col_data = col_data)\n",
    "\n",
    "# F.fastqtonumber()\n",
    "# F.plotBarChartUnmapped()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:19.605802Z",
     "start_time": "2020-05-14T17:11:19.596174Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class countContigs():\n",
    "    def __init__(self, NF_out, col_data):\n",
    "        self.NF_out = NF_out\n",
    "        self.wkdir = f'{self.NF_out}/unmapped/final'\n",
    "        self.col_data = col_data\n",
    "        \n",
    "    def countContig(self,f):\n",
    "        df = pd.read_csv(f,sep=\"\\t\")\n",
    "        length = len(df)\n",
    "        return length\n",
    "    \n",
    "    def collectContigs(self):\n",
    "\n",
    "#         out = glob.glob{f'{self.wkdir}/filter/contigs/\n",
    "        levels = [\"all\",\"group\",\"single\"]\n",
    "        removelist = [\"9606\",\"10090\",\"Chordata\",\"Viridiplantae\",\"Artificial\"]\n",
    "        cols = [\"sample\",\"initial_contigs\"]\n",
    "        df = pd.DataFrame(columns=cols)\n",
    "\n",
    "        \n",
    "        samples = []\n",
    "        lengths = []\n",
    "        for level in levels:\n",
    "            files = glob.glob(f\"{self.wkdir}/filter/contigs/blast/initial_contigs/{level}/*_contigs.txt\")   \n",
    "\n",
    "            for f in sorted(files):\n",
    "                name = os.path.basename(f).replace(\"_unmapped_initial_contigs.txt\",\"\")\n",
    "                length = self.countContig(f)\n",
    "                samples.append(name)\n",
    "                lengths.append(length)\n",
    "\n",
    "        df[\"sample\"] = samples\n",
    "        df[\"initial_contigs\"] = lengths\n",
    "\n",
    "        for remove in removelist:\n",
    "            lengths = []                     \n",
    "            for level in levels:\n",
    "                files = glob.glob(f\"{self.wkdir}/filter/contigs/blast/Removed_afterBlast_{remove}/{level}/*.txt\")\n",
    "                for f in sorted(files):\n",
    "                    name = os.path.basename(f).replace(f\"_{remove}.txt\",\"\")\n",
    "\n",
    "                    length = self.countContig(f)\n",
    "                    lengths.append(length)\n",
    "            if remove == \"9606\":\n",
    "                remove = \"human\"\n",
    "            if remove == \"10090\":\n",
    "                remove = \"mouse\"\n",
    "            df[remove] = lengths\n",
    "\n",
    "        df.to_csv(f'{self.wkdir}/filter/contigs/blast/contigs_amount_df.txt',sep=\"\\t\",index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:20.997003Z",
     "start_time": "2020-05-14T17:11:20.994801Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# col_data = \"/Users/m/Google_Drive/Scripts/2019/biome/biome_shared/general/datasets/Z_RNAseq-Biome-master/sample_table.txt\"\n",
    "# NF_out = \"/Users/m/Google_Drive/Scripts/2019/biome/biome_shared/general/datasets/Z_RNAseq-Biome-master/NF_OUT\"\n",
    "\n",
    "# C = countContigs(NF_out = NF_out, col_data = col_data)\n",
    "# C.collectContigs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:21.360614Z",
     "start_time": "2020-05-14T17:11:21.349652Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class DarkBiomeCount():\n",
    "    def __init__(self, NF_out):\n",
    "        self.NF_out = NF_out\n",
    "        self.wkdir = f'{self.NF_out}/unmapped/final'\n",
    "        self.df = pd.DataFrame()\n",
    "        self.df[\"file\"] = \"\"\n",
    "        self.df[\"initial\"] = \"\"\n",
    "        self.df[\"afterDust\"] = \"\"\n",
    "        self.df[\"afterVec\"] = \"\"\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    " \n",
    "    def readFiles(self, count_step):\n",
    "        files = sorted(glob.glob(f\"{self.wkdir}/darkbiome/{count_step}/*/*\") )\n",
    "        counts = []\n",
    "        names = []\n",
    "        for file in files:\n",
    "            name = os.path.basename(file)\n",
    "            x = self.fastaCount(file)\n",
    "            counts.append(x)\n",
    "            names.append(name)\n",
    "        self.df[count_step] = counts\n",
    "        self.df[\"file\"] = names\n",
    "\n",
    "            \n",
    "            \n",
    "    def fastaCount(self,file):\n",
    "        with open(file,\"r\") as infile:\n",
    "            x = 0\n",
    "            for line in infile:\n",
    "                if \">\" in line:\n",
    "                    x += 1 \n",
    "                    if \"DUMMY\" in line:\n",
    "                        x -= 1\n",
    "            return x\n",
    "        \n",
    "    def runDarkBiomeCount(self):\n",
    "        self.readFiles(count_step=\"initial\")\n",
    "        self.readFiles(count_step=\"afterDust\")\n",
    "        self.readFiles(count_step=\"afterVec\")\n",
    "        self.df.to_csv(f\"{self.wkdir}/darkbiome/contigs_amount_dark_df.txt\",sep=\"\\t\", index=None)\n",
    "                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:22.377133Z",
     "start_time": "2020-05-14T17:11:22.374655Z"
    }
   },
   "outputs": [],
   "source": [
    "# NF = \"/Users/m/Google_Drive/Scripts/2019/biome/biome_shared/general/datasets/Z_RNAseq-Biome-master\"\n",
    "\n",
    "# NF_out = f\"{NF}/NF_OUT\" \n",
    "\n",
    "# D = DarkBiomeCount(NF_out=NF_out)\n",
    "# D.runDarkBiomeCount()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:25.032984Z",
     "start_time": "2020-05-14T17:11:25.020461Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class lastDBdiff():\n",
    "    def __init__(self, NF_out):\n",
    "        self.NF_out = NF_out\n",
    "        self.wkdir = f'{self.NF_out}/unmapped/final/darkbiome'\n",
    "        \n",
    "        \n",
    "    def dfDIFF(self,files,files2, outfile, level,trimend):\n",
    "        for x in range(len(files)):\n",
    "            f = files[x]\n",
    "            f = os.path.basename(f)\n",
    "            l = len(trimend)\n",
    "            print(\"working on: \", f)\n",
    "            name = f'{f[:-l]}'\n",
    "            df = pd.read_csv(files[x],sep=\"\\t\")\n",
    "            df2 = pd.read_csv(files2[x],sep=\"\\t\")\n",
    "            L = len(df) - len(df2)\n",
    "            outfile.write(f'{name}\\t{level}\\tBIOME\\tRegular_vs_LASTDB\\t{L}\\n')\n",
    "\n",
    "            \n",
    "            \n",
    "    def fastaCount(self,file):\n",
    "        with open(file,\"r\") as infile:\n",
    "            x = 0\n",
    "            for line in infile:\n",
    "                if \">\" in line:\n",
    "                    x += 1 \n",
    "                    if \"DUMMY\" in line:\n",
    "                        x -= 1\n",
    "            return x\n",
    "            \n",
    "    def fa_DIFF(self,files,files2, outfile, level,trimend):\n",
    "        for x in range(len(files)):\n",
    "            \n",
    "            f = files[x]\n",
    "            f = os.path.basename(f)\n",
    "            l = len(trimend)\n",
    "            name = f'{f[:-l]}'\n",
    "            fa_count = self.fastaCount(files[x])\n",
    "\n",
    "    \n",
    "#             df2 = pd.read_csv(files2[x],sep=\"\\t\")\n",
    "#             count2 = len(df2)\n",
    "            fa_count2 = self.fastaCount(files2[x])\n",
    "            L = fa_count - fa_count2\n",
    "            outfile.write(f'{name}\\t{level}\\t{fa_count}\\t{fa_count2}\\t{L}\\n')            \n",
    "    \n",
    "    def amountDarkLASTDB(self):\n",
    "        print(\"Running \")\n",
    "          #Same for Dark genome \n",
    "        \n",
    "        f_single = sorted(glob.glob(f'{self.wkdir}/afterVec/single/*biome.fasta'))\n",
    "        single_FG = sorted(glob.glob(f'{self.wkdir}/lastdb/lastdb_fasta/group_single/single/*.fasta'))\n",
    "\n",
    "        f_group = sorted(glob.glob(f'{self.wkdir}/afterVec/group/*biome.fasta'))\n",
    "        group_FA = sorted(glob.glob(f'{self.wkdir}/lastdb/lastdb_fasta/all_group/group/*.fasta'))\n",
    "        \n",
    "        f_all = sorted(glob.glob(f'{self.wkdir}/afterVec/all/*biome.fasta'))        \n",
    "        all_FG = sorted(glob.glob(f'{self.wkdir}/lastdb/lastdb_fasta/all_group/all/*.fasta'))\n",
    "\n",
    "\n",
    "        fout = f'{self.wkdir}/contigs_amount_dark_lastdb_df.txt'\n",
    "        with open(fout,\"w\") as outfile:\n",
    "\n",
    "            trimend = \"_darkbiome.fasta\"\n",
    "            outfile.write(f'file\\tlevel\\t\\tamount_afterDust\\tamount_lastdb\\tamount_removed\\n') \n",
    "            self.fa_DIFF(f_single,single_FG,outfile,\"single_FG\",trimend)\n",
    "            self.fa_DIFF(f_group,group_FA,outfile,\"group_FA\",trimend)\n",
    "            self.fa_DIFF(f_all,all_FG,outfile,\"all_FG\",trimend)\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:26.616904Z",
     "start_time": "2020-05-14T17:11:26.614686Z"
    }
   },
   "outputs": [],
   "source": [
    "# NF = \"/Users/m/Google_Drive/Scripts/2019/biome/biome_shared/general/datasets/Z_RNAseq-Biome-master\"\n",
    "\n",
    "# NF_out = f\"{NF}/NF_OUT\" \n",
    "# D = lastDBdiff(NF_out=NF_out)\n",
    "# # D.amountLASTDB()\n",
    "# D.amountDarkLASTDB()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:27.843940Z",
     "start_time": "2020-05-14T17:11:27.837062Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class amountDark():\n",
    "    def __init__(self, NF_out):\n",
    "        self.NF_out = NF_out\n",
    "        self.wkdir = f'{self.NF_out}/unmapped/final/darkbiome'\n",
    "        \n",
    "        \n",
    "    def readDF(self, f):\n",
    "        try:\n",
    "            df = pd.read_csv(f,sep=\"\\t\")\n",
    "            df = df[~df[\"contig\"].str.contains(\"DUMMY\")]\n",
    "#             DUMMYDARK\n",
    "            \n",
    "            count_all = len(df)\n",
    "        except:\n",
    "            count_all = 0\n",
    "        return count_all\n",
    "        \n",
    "\n",
    "        \n",
    "    def runDark(self):\n",
    "\n",
    "        x_nohit = self.readDF(f\"{self.wkdir}/lastdb/FINAL_Nohits/all_group/all/all_darkbiome_df.txt\" )\n",
    "        \n",
    "        tophits = \"lastdb/FINAL_Tophits/all_group/all/blastXhits\"\n",
    "        x_art = self.readDF(f\"{self.wkdir}/{tophits}/all_darkb_Artificial.txt\" )\n",
    "        x_cho = self.readDF(f\"{self.wkdir}/{tophits}/all_darkb_Chordata.txt\" )\n",
    "        x_vir = self.readDF(f\"{self.wkdir}/{tophits}/all_darkb_Viridiplantae.txt\" )\n",
    "        x_top = self.readDF(f\"{self.wkdir}/lastdb/FINAL_Tophits/all_group/all/all_darkbiome_df.txt\")\n",
    "        \n",
    "        with open(f\"{self.wkdir}/contigs_amount_dark_afterblast.txt\",\"w\") as outfile:\n",
    "            outfile.write(f\"step\\tamount\\nFinal_No_Hits\\t{x_nohit}\\nFinal_Artificial\\t{x_art}\\nFinal_Chordata\\t{x_cho}\\nFinal_Viridiplantae\\t{x_vir}\\nFinal_Hits\\t{x_top}\"\n",
    "            )\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:30.064227Z",
     "start_time": "2020-05-14T17:11:30.061373Z"
    }
   },
   "outputs": [],
   "source": [
    "# D = amountDark(NF_out=NF_out)\n",
    "# D.runDark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:30.472534Z",
     "start_time": "2020-05-14T17:11:30.468814Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import argparse\n",
    "def parse_arguments():\n",
    "        parser = argparse.ArgumentParser(description='filter quantify and graph')\n",
    "        parser.add_argument('--col_data', action= 'store', metavar='col_data')  \n",
    "        parser.add_argument('--Nextflow_Out', action= 'store', metavar='--Nextflow_Out') \n",
    "        args = parser.parse_args()\n",
    "        return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:34.838187Z",
     "start_time": "2020-05-14T17:11:34.791557Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--col_data col_data]\n",
      "                             [--Nextflow_Out --Nextflow_Out]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/m/Library/Jupyter/runtime/kernel-1b9e6412-79c6-44ac-a6bc-74c18159b87b.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/m/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3333: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "if __name__==\"__main__\":\n",
    "    args = parse_arguments()\n",
    "    col_data = args.col_data\n",
    "    NF_out = args.Nextflow_Out\n",
    "    \n",
    "    \n",
    "    F = fastQ(NF_out = NF_out, col_data = col_data)\n",
    "    F.fastqtonumber()\n",
    "    \n",
    "    \n",
    "    C = countContigs(NF_out = NF_out, col_data = col_data)\n",
    "    C.collectContigs()\n",
    "    \n",
    "\n",
    "    D = DarkBiomeCount(NF_out=NF_out)\n",
    "    D.runDarkBiomeCount()\n",
    "    \n",
    "    D = lastDBdiff(NF_out=NF_out)\n",
    "    D.amountDarkLASTDB()\n",
    "    \n",
    "    D = amountDark(NF_out=NF_out)\n",
    "    D.runDark()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:36.814761Z",
     "start_time": "2020-05-14T17:11:36.432406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4.0-CountContigs.ipynb to nb_4.0-CountContigs.py\r\n"
     ]
    }
   ],
   "source": [
    "import fire\n",
    "!python notebook2script.py 4.0-CountContigs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
